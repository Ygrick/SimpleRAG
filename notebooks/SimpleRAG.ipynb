{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install evaluate==0.4.3 bert-score==0.3.13\n",
    "# Остальные зависимости в requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from evaluate import load\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зададим константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert-score для подсчёта метрики\n",
    "BERTSCORE = load(\"bertscore\")\n",
    "\n",
    "# Датасет с Hugging Face\n",
    "DATASET = \"neural-bridge/rag-dataset-1200\"\n",
    "SPLIT_DATASET = \"test\"\n",
    "\n",
    "# Модели\n",
    "## Загружаем модель эмбедингов\n",
    "EMBEDDING_MODEL = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-large\",\n",
    "    model_kwargs={\"device\": device}\n",
    ")\n",
    "\n",
    "# Бесплатное API к LLM от сервиса https://openrouter.ai/api/v1\n",
    "## Определяем модель для генерации ответа на основе документов\n",
    "# LLM_MODEL = \"meta-llama/llama-3.2-3b-instruct:free\"\n",
    "## API-конфигурация к LLM\n",
    "# CLIENT = OpenAI(\n",
    "#     base_url=\"https://openrouter.ai/api/v1\", \n",
    "#     api_key=os.getenv(\"TOKEN_OPENAI\")\n",
    "# )\n",
    "\n",
    "# Бесплатное API к LLM от сервиса https://api.together.xyz/v1\n",
    "## Определяем модель для генерации ответа на основе документов\n",
    "LLM_MODEL = \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"\n",
    "## API-конфигурация к LLM\n",
    "CLIENT = OpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\", \n",
    "    api_key=os.getenv(\"TOKEN_TAI\")\n",
    ")\n",
    "\n",
    "# Создадим два промпта для уменьшения вероятности нерелевантного ответа\n",
    "\n",
    "## Промпт для LLM, который просит определить только релевантные документы\n",
    "DOC_RETRIEVAL_PROMPT = (\n",
    "    \"You are an AI assistant specialized in document retrieval. \"\n",
    "    \"Your task is to extract only the most relevant document IDs and chunk IDs from the provided documents. \"\n",
    "    \"Strictly follow these rules: \"\n",
    "    \"1. Return only a JSON object in this exact format: \"\n",
    "    '{\"relevant_documents\": [{\"document_id\": <doc_id>, \"chunk_id\": <chunk_id>}, ...]}. '\n",
    "    \"2. Do not modify, summarize, or explain the documents. \"\n",
    "    \"3. Do not include any additional text, explanations, reasoning, or commentary. \"\n",
    "    \"4. Do not return the document content, only IDs. \"\n",
    "    \"5. If no relevant documents exist, return an empty JSON: {\\\"relevant_documents\\\": []}. \"\n",
    "    \"6. Any deviation from these rules is strictly prohibited.\"\n",
    ")\n",
    "\n",
    "## Промпт для LLM, который просит составить ответ только на релевантных документах\n",
    "ANSWER_GENERATION_PROMPT = (\n",
    "    \"You are an assistant that answers user questions based strictly on the provided documents. \"\n",
    "    \"Use only the content from the relevant documents and chunks listed below: \"\n",
    "    \"{retrieved_data} \"\n",
    "    \"Now, generate a well-structured answer to the user's question.\"\n",
    "    \"Do not make up information. If the answer is unclear from the documents, say 'Insufficient information'.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определим данные и создадим базу знаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answer'],\n",
       "    num_rows: 240\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset example:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': 'Trail Patrol Training\\nWant to be a part of the Trail Patrol ?? Join an Orientation & Hike on the 1st Tuesday of each month. This course is required for all PATC members interested in joining the PATC Trail Patrol.\\nThe course teaches the essential skills necessary to be a trail patrol member and to provide a reassuring presence on the trail while teaching safety and environmental responsibility. A Trail Patrol handbook is provided to all students. Please bring a pencil, your hiking daypack & lunch.\\nMore Info: View the Calendar or contact TP Training or visit the Trail Patrol Training web pages.\\nHike Leader Class.\\nMore Info: Contact Hike Leader Training or click here to register.\\nBackpacking Classes\\nEducating people in safe and environmentally friendly practices for traveling into the backcountry is one of Trail Patrol’s core responsibilities. We offer backpacking classes for novices seeking to take up backpacking as well as for experienced backpackers.\\nBackpacking 101: An Introductory Course is for beginners & those who want to update rusty skills. It includes a weekend overnight backpacking trip. Instruction covers equipment selection and use, information and techniques to enhance safety and comfort, and Leave No Trace methods to protect our fragile backcountry environment.\\nMore Info: Contact Backpacking Training or click here to register.\\nBackpacking 202: Planning and leading group trips is for Backpacking 101 graduates and others with comparable experience. This class provides the opportunity to take it to the next level by developing special skill needed to plan and lead group trips. Pre-trip planning sessions will cover equipment selection and use, route planning, food planning, improving safety and comfort, managing the unexpected, and Leave No Trace principles to protect our fragile backcountry environment.\\nIncludes a weekend overnight backpacking trip.\\nMore Info: Contact Backpacking Training or click here to register.\\nLightweight Backpacking: Techniques for reducing pack weight without compromising safety - for both experienced and new backpackers. One-day workshop, no backpacking trip. This one-day workshop is designed to acquaint backpackers with the importance of weight considerations when choosing and using equipment, and to instill a weight-conscience mind set when packing for an overnight trip. It is not intended to advocate an ultra light philosophy. Each student attending the class will be encouraged to bring a pack fully loaded, less food and water, with everything they would normally carry on a 3-day, 2-night trip of 10\\nPre-registration is required. Class is limited to 25 students.\\nMore Info: Contact Backpacking Training or click here to register.\\nWilderness First Aid\\nBasic Wilderness First Aid (BWFA) is a 2-day workshop. Day one covers Adult CPR and AED and American Heart Association First Aid. You will receive a textbook and a certification card good for two years. Day two is American Safety and Health Institute (ASHI) Basic Wilderness First Aid. You will learn how to do bleeding control, splinting and other basic first aid skills in the wilderness setting. There is plenty of hands-on time & paramedics with years of backcountry experience teach the classes.\\nMore Info: Contact TP First Aid or click here to register.\\nWilderness First Aid (WFA)\\nJoin us for a 20-hour Wilderness First Aid Class! In this class, you will learn how to get help, move and transport patients, conduct patient assessments, documentation, how to handle medical and environmental emergencies, injury prevention and care, and much more. There is plenty of hands-on practice time as well as scenarios. This class is conducted inside and outside on the trail. Each student will receive a certification card good for two years through ECSI and a waterproof field guide. No experience required.\\nMore Info: Contact TP First Aid or click here to register.\\nLeave No Trace Trainer Course\\nThese courses are designed to enhance your understanding of Leave No Trace practices and ethics and to increase your level of expertise and confidence in teaching Leave No Trace skills. Through focused activities, hands‑on field experience and both formal and informal discussions, you will be introduced to concepts and methods that will advance your knowledge of Leave No Trace issues, expand your repertoire of low‑impact skills and increase your effectiveness in teaching these important skills to others.\\nOn completion of this course, participants will be registered as Leave No Trace Trainers with the national Leave No Trace Center for Outdoor Ethics and will receive a certificate of course completion as well as their Leave No Trace Trainer lapel pin.\\nMore Info: Contact TP LNT or click here to register.',\n",
       " 'question': 'What are some of the skills taught in the Trail Patrol Training course?',\n",
       " 'answer': 'The course teaches the essential skills necessary to be a trail patrol member and to provide a reassuring presence on the trail while teaching safety and environmental responsibility.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем данные и смотрим что в них\n",
    "rag_dataset = load_dataset(DATASET, split=SPLIT_DATASET)\n",
    "display(rag_dataset)\n",
    "\n",
    "# Смотрим пример одного row\n",
    "print('Dataset example:') \n",
    "rag_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_documents(documents: List[str], chunk_size: int = 1000, chunk_overlap: int = 100) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Разбивает документы на чанки.\n",
    "\n",
    "    Args:\n",
    "        documents (List[Document]): Список документов.\n",
    "        chunk_size (int): Размер чанка в символах.\n",
    "        chunk_overlap (int): Перекрытие чанков.\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: Разбитые на чанки документы.\n",
    "    \"\"\"\n",
    "    print(f\"Разбиваем {len(documents)} документов на чанки (размер: {chunk_size}, перекрытие: {chunk_overlap})\")\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunked_documents = []\n",
    "\n",
    "    # Предобработка всех текстовых файлов\\документов\\текстов\n",
    "    for i, document in enumerate(documents):\n",
    "        # Минимально очистим текст\n",
    "        text = re.sub(r'(\\r\\n|\\r|\\n){2,}', r'\\n', document)  # Удаляем лишние пустые строки\n",
    "        text = re.sub(r'[ \\t]+', ' ', text)  # Заменяем табуляции на пробелы\n",
    "        text = text.strip()\n",
    "\n",
    "        # Создадим langchain-документ (совместимый формат для RecursiveCharacterTextSplitter)\n",
    "        langchain_document = Document(page_content=text)\n",
    "        # Разобьём длинный текст на чанки\n",
    "        chunks = text_splitter.split_documents([langchain_document])\n",
    "\n",
    "        # Добавим номер документа (текста) и номер чанка как доп.информацию\n",
    "        # И добавим сам чанк в список всех чанков\n",
    "        for j, chunk in enumerate(chunks):\n",
    "            chunk.metadata[\"document_id\"] = i + 1\n",
    "            chunk.metadata[\"chunk_id\"] = j + 1\n",
    "            chunked_documents.append(chunk)\n",
    "\n",
    "    print(f\"Создано {len(chunked_documents)} чанков\")\n",
    "    return chunked_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retriever(documents: List[Document], weights: List[float] = [0.4, 0.6]) -> EnsembleRetriever:\n",
    "    \"\"\"\n",
    "    Создаёт EnsembleRetriever на основе FAISS и BM25.\n",
    "\n",
    "    Args:\n",
    "        documents (List[Document]): Список документов для индексации.\n",
    "        weights (List[float]): Веса для каждого из retrievers\n",
    "\n",
    "    Returns:\n",
    "        EnsembleRetriever: Комбинированный ретривер для поиска.\n",
    "    \"\"\"\n",
    "    # FAISS retriever (векторный поиск по эмбеддингам)\n",
    "    vector_store = FAISS.from_documents(documents, EMBEDDING_MODEL)\n",
    "    faiss_retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={'k': 2}  # Количество возвращаемых документов\n",
    "    )\n",
    "\n",
    "    # BM25 retriever (традиционный текстовый поиск) \n",
    "    # *В основном используется для поиска по специфичным аббревиатурам домена. \n",
    "    # *Для данного датасета является излишеством, использован в качестве примера.\n",
    "    bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "    bm25_retriever.k = 2  # Количество возвращаемых документов\n",
    "\n",
    "    # Объединяем их в EnsembleRetriever\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[bm25_retriever, faiss_retriever],\n",
    "        weights=weights  # Вес каждого retriever\n",
    "    )\n",
    "\n",
    "    return ensemble_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Разбиваем 240 документов на чанки (размер: 1000, перекрытие: 100)\n",
      "Создано 1139 чанков\n",
      "\n",
      "Пример чанка:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'document_id': 1, 'chunk_id': 4}, page_content='More Info: Contact Backpacking Training or click here to register.\\nWilderness First Aid\\nBasic Wilderness First Aid (BWFA) is a 2-day workshop. Day one covers Adult CPR and AED and American Heart Association First Aid. You will receive a textbook and a certification card good for two years. Day two is American Safety and Health Institute (ASHI) Basic Wilderness First Aid. You will learn how to do bleeding control, splinting and other basic first aid skills in the wilderness setting. There is plenty of hands-on time & paramedics with years of backcountry experience teach the classes.\\nMore Info: Contact TP First Aid or click here to register.\\nWilderness First Aid (WFA)')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_documents = chunk_documents(rag_dataset['context'])\n",
    "print(\"\\nПример чанка:\")\n",
    "chunked_documents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = create_retriever(chunked_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Убедимся что всё работает на тестовом примере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестовый запрос: Who were the two convicted killers that escaped from an upstate New York maximum-security prison?\n"
     ]
    }
   ],
   "source": [
    "# Пример запроса\n",
    "test_query = rag_dataset['question'][3]\n",
    "print(\"Тестовый запрос:\", test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(system_prompt: str, docs: str, query: str, temperature: float = 0.0) -> str:\n",
    "    \"\"\"\n",
    "    Отправляет запрос в LLM, используя заданный системный промпт.\n",
    "\n",
    "    Args:\n",
    "        system_prompt (str): Промпт, определяющий задачу для модели.\n",
    "        docs (str): Документы в формате JSON, содержащие релевантную информацию.\n",
    "        query (str): Вопрос пользователя.\n",
    "        temperature (float): Температура ответа (насколько модель креативна)\n",
    "\n",
    "    Returns:\n",
    "        str: Ответ LLM.\n",
    "    \"\"\"\n",
    "    # Формируем контекст для LLM\n",
    "    chat_history = [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "        {'role': 'documents', 'content': docs},\n",
    "        {'role': 'user', 'content': query}\n",
    "    ]\n",
    "\n",
    "    # Отправляем запрос в LLM и возвращаем ответ\n",
    "    response = CLIENT.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=chat_history,\n",
    "        temperature=temperature,\n",
    "        max_tokens=2048\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск релевантных документов для тестового запроса\n",
    "relevant_docs = ensemble_retriever.invoke(test_query)\n",
    "\n",
    "# Преобразуем найденные документы в нужный нам формат\n",
    "relevant_docs_data = [\n",
    "    {\n",
    "        \"document_id\": doc.metadata.get(\"document_id\", -1),\n",
    "        \"chunk_id\": doc.metadata.get(\"chunk_id\", -1),\n",
    "        \"content\": doc.page_content\n",
    "    }\n",
    "    for doc in relevant_docs\n",
    "]\n",
    "json_docs = json.dumps(relevant_docs_data, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полученные идентификаторы документов: {\"relevant_documents\": [{\"document_id\": 4, \"chunk_id\": 1}]\n"
     ]
    }
   ],
   "source": [
    "# Первый запрос к LLM: получение списка ID релевантных документов\n",
    "id_docs_response = get_llm_response(\n",
    "    system_prompt=DOC_RETRIEVAL_PROMPT, \n",
    "    docs=json_docs, \n",
    "    query=test_query,\n",
    "    temperature=0.0 # Жёсткий режим для строгого ответа\n",
    ")\n",
    "print(f\"Полученные идентификаторы документов: {id_docs_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный ответ: The two convicted killers who escaped from an upstate New York maximum-security prison were Richard Matt and David Sweat. Richard Matt was serving 25 years to life for killing and dismembering his former boss, while David Sweat was serving a sentence of life without parole for killing a sheriff's deputy in Broome County in 2002.\n",
      "\n",
      "Эталонный ответ: The two convicted killers that escaped from an upstate New York maximum-security prison were Richard Matt and David Sweat.\n"
     ]
    }
   ],
   "source": [
    "# Второй запрос к LLM: генерация финального ответа\n",
    "response = get_llm_response(\n",
    "    system_prompt=ANSWER_GENERATION_PROMPT.format(retrieved_data=id_docs_response), \n",
    "    docs=json_docs, \n",
    "    query=test_query,\n",
    "    temperature=0.3 # Разрешаем быть слегка креативными\n",
    ")\n",
    "print(\"Сгенерированный ответ:\", response)\n",
    "print(\"\\nЭталонный ответ:\", rag_dataset[3]['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим насколько качественно работает наша RAG система"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are some of the features of the yellow pa...</td>\n",
       "      <td>The yellow paper plates mentioned in the conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is a \"Cultural Muslim\" according to Kaigh...</td>\n",
       "      <td>A \"Cultural Muslim\" is someone who calls thems...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who are the main characters in the book \"Odd a...</td>\n",
       "      <td>The main characters in the book \"Odd and the F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are some features of the WHIRLPOOL BATHTU...</td>\n",
       "      <td>The WHIRLPOOL BATHTUB model AM152JDTS-1Z has s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the rank of Iasi in terms of populatio...</td>\n",
       "      <td>Iasi is the 4th biggest city in Romania in ter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are some of the features of the yellow pa...   \n",
       "1  What is a \"Cultural Muslim\" according to Kaigh...   \n",
       "2  Who are the main characters in the book \"Odd a...   \n",
       "3  What are some features of the WHIRLPOOL BATHTU...   \n",
       "4  What is the rank of Iasi in terms of populatio...   \n",
       "\n",
       "                                              answer  \n",
       "0  The yellow paper plates mentioned in the conte...  \n",
       "1  A \"Cultural Muslim\" is someone who calls thems...  \n",
       "2  The main characters in the book \"Odd and the F...  \n",
       "3  The WHIRLPOOL BATHTUB model AM152JDTS-1Z has s...  \n",
       "4  Iasi is the 4th biggest city in Romania in ter...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Положим вопросы и ответы в датафрейм и возьмём лишь 20 примеров (т.к. API имеет лимиты)\n",
    "df = pd.DataFrame({\n",
    "    'question': rag_dataset['question'],\n",
    "    'answer': rag_dataset['answer'],\n",
    "})\n",
    "df_sample = df.sample(100, random_state=42)\n",
    "df_sample.reset_index(drop=True, inplace=True)\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Генерирует ответ на заданный запрос, используя retriever, документы и LLM.\n",
    "\n",
    "    Аргументы:\n",
    "        query (str): Вопрос пользователя.\n",
    "\n",
    "    Возвращает:\n",
    "        str: Сгенерированный ответ модели.\n",
    "    \"\"\"\n",
    "    # Поиск релевантных документов\n",
    "    relevant_docs = ensemble_retriever.invoke(query)\n",
    "    relevant_docs_data = [\n",
    "        {\n",
    "            \"document_id\": doc.metadata.get(\"document_id\", -1),\n",
    "            \"chunk_id\": doc.metadata.get(\"chunk_id\", -1),\n",
    "            \"content\": doc.page_content\n",
    "        }\n",
    "        for doc in relevant_docs\n",
    "    ]\n",
    "    json_docs = json.dumps(relevant_docs_data, ensure_ascii=False)\n",
    "    \n",
    "    # Первый запрос: получение релевантных ID документов\n",
    "    id_docs_response = get_llm_response(\n",
    "        system_prompt=DOC_RETRIEVAL_PROMPT, \n",
    "        docs=json_docs, \n",
    "        query=query,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    # Задержка для соблюдения лимитов API\n",
    "    time.sleep(10)\n",
    "    # Второй запрос: генерация ответа на основе релевантных документов\n",
    "    response = get_llm_response(\n",
    "        system_prompt=ANSWER_GENERATION_PROMPT.format(retrieved_data=id_docs_response), \n",
    "        docs=json_docs, \n",
    "        query=query,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    # Задержка для соблюдения лимитов API\n",
    "    time.sleep(10)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>rag_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are some of the features of the yellow pa...</td>\n",
       "      <td>The yellow paper plates mentioned in the conte...</td>\n",
       "      <td>The features of the yellow paper plates mentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is a \"Cultural Muslim\" according to Kaigh...</td>\n",
       "      <td>A \"Cultural Muslim\" is someone who calls thems...</td>\n",
       "      <td>According to Kaighla Um Dayo, a!Cultural Musli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who are the main characters in the book \"Odd a...</td>\n",
       "      <td>The main characters in the book \"Odd and the F...</td>\n",
       "      <td>The main characters in the book \"Odd and the F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are some features of the WHIRLPOOL BATHTU...</td>\n",
       "      <td>The WHIRLPOOL BATHTUB model AM152JDTS-1Z has s...</td>\n",
       "      <td>The WHIRLPOOL BATHTUB model AM152JDTS-1Z has t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the rank of Iasi in terms of populatio...</td>\n",
       "      <td>Iasi is the 4th biggest city in Romania in ter...</td>\n",
       "      <td>Iasi is the 4th biggest city in Romania in ter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are some of the features of the yellow pa...   \n",
       "1  What is a \"Cultural Muslim\" according to Kaigh...   \n",
       "2  Who are the main characters in the book \"Odd a...   \n",
       "3  What are some features of the WHIRLPOOL BATHTU...   \n",
       "4  What is the rank of Iasi in terms of populatio...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The yellow paper plates mentioned in the conte...   \n",
       "1  A \"Cultural Muslim\" is someone who calls thems...   \n",
       "2  The main characters in the book \"Odd and the F...   \n",
       "3  The WHIRLPOOL BATHTUB model AM152JDTS-1Z has s...   \n",
       "4  Iasi is the 4th biggest city in Romania in ter...   \n",
       "\n",
       "                                          rag_answer  \n",
       "0  The features of the yellow paper plates mentio...  \n",
       "1  According to Kaighla Um Dayo, a!Cultural Musli...  \n",
       "2  The main characters in the book \"Odd and the F...  \n",
       "3  The WHIRLPOOL BATHTUB model AM152JDTS-1Z has t...  \n",
       "4  Iasi is the 4th biggest city in Romania in ter...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['rag_answer'] = df_sample['question'].apply(rag_answer)\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bertscore(predictions: List[str], references: List[str], lang: str = \"en\") -> float:\n",
    "    \"\"\"\n",
    "    Вычисляет средний F1-скор BertScore между предсказанными и эталонными ответами.\n",
    "\n",
    "    Аргументы:\n",
    "        predictions (List[str]): Список сгенерированных моделью ответов.\n",
    "        references (List[str]): Список эталонных (правильных) ответов.\n",
    "        lang (str): Язык текстов (по умолчанию \"en\").\n",
    "\n",
    "    Возвращает:\n",
    "        float: Средний F1 из BertScore.\n",
    "    \"\"\"\n",
    "    results = BERTSCORE.compute(predictions=predictions, references=references, lang=lang)\n",
    "    return float(np.mean(results[\"f1\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertScore F1 (с дополнительной проверкой релевантности): 0.9312\n"
     ]
    }
   ],
   "source": [
    "avg_f1 = compute_bertscore(df_sample['rag_answer'].tolist(), df_sample['answer'].tolist())\n",
    "print(f\"BertScore F1 (с дополнительной проверкой релевантности): {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим будет ли результат лучше, если мы уберем дополнительную проверку на релевантность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer_v2(query):\n",
    "    \"\"\"\n",
    "    Генерирует ответ на заданный запрос, используя retriever, документы и LLM.\n",
    "    Отличие: отсутствует дополнительная проверка релевантности документов.\n",
    "\n",
    "    Аргументы:\n",
    "        query (str): Вопрос пользователя.\n",
    "\n",
    "    Возвращает:\n",
    "        str: Сгенерированный ответ модели.\n",
    "    \"\"\"\n",
    "    # Поиск релевантных документов\n",
    "    relevant_docs = ensemble_retriever.invoke(query)\n",
    "    relevant_docs_data = [\n",
    "        {\n",
    "            \"document_id\": doc.metadata.get(\"document_id\", -1),\n",
    "            \"chunk_id\": doc.metadata.get(\"chunk_id\", -1),\n",
    "            \"content\": doc.page_content\n",
    "        }\n",
    "        for doc in relevant_docs\n",
    "    ]\n",
    "    json_docs = json.dumps(relevant_docs_data, ensure_ascii=False)\n",
    "    \n",
    "    # Формируем промпт без шага фильтрации релевантности\n",
    "    system_prompt = (\n",
    "        \"You are an assistant that answers user questions based strictly on the provided documents. \"\n",
    "        \"Use only the content from the relevant documents.\"\n",
    "        \"Now, generate a well-structured answer to the user's question.\"\n",
    "        \"Do not make up information. If the answer is unclear from the documents, say 'Insufficient information'.\"\n",
    "    )\n",
    "    response = get_llm_response(\n",
    "        system_prompt=system_prompt, \n",
    "        docs=json_docs, \n",
    "        query=query,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    # Задержка для соблюдения лимитов API\n",
    "    time.sleep(10)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>rag_answer</th>\n",
       "      <th>rag_answer_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are some of the features of the yellow pa...</td>\n",
       "      <td>The yellow paper plates mentioned in the conte...</td>\n",
       "      <td>The features of the yellow paper plates mentio...</td>\n",
       "      <td>The features of the yellow paper plates mentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is a \"Cultural Muslim\" according to Kaigh...</td>\n",
       "      <td>A \"Cultural Muslim\" is someone who calls thems...</td>\n",
       "      <td>According to Kaighla Um Dayo, a!Cultural Musli...</td>\n",
       "      <td>According to Kaighla Um Dayo, a \"Cultural Musl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who are the main characters in the book \"Odd a...</td>\n",
       "      <td>The main characters in the book \"Odd and the F...</td>\n",
       "      <td>The main characters in the book \"Odd and the F...</td>\n",
       "      <td>The main characters in the book \"Odd and the F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are some features of the WHIRLPOOL BATHTU...</td>\n",
       "      <td>The WHIRLPOOL BATHTUB model AM152JDTS-1Z has s...</td>\n",
       "      <td>The WHIRLPOOL BATHTUB model AM152JDTS-1Z has t...</td>\n",
       "      <td>The WHIRLPOOL BATHTUB model AM152JDTS-1Z has t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the rank of Iasi in terms of populatio...</td>\n",
       "      <td>Iasi is the 4th biggest city in Romania in ter...</td>\n",
       "      <td>Iasi is the 4th biggest city in Romania in ter...</td>\n",
       "      <td>Iasi is the 4th biggest city in Romania in ter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are some of the features of the yellow pa...   \n",
       "1  What is a \"Cultural Muslim\" according to Kaigh...   \n",
       "2  Who are the main characters in the book \"Odd a...   \n",
       "3  What are some features of the WHIRLPOOL BATHTU...   \n",
       "4  What is the rank of Iasi in terms of populatio...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The yellow paper plates mentioned in the conte...   \n",
       "1  A \"Cultural Muslim\" is someone who calls thems...   \n",
       "2  The main characters in the book \"Odd and the F...   \n",
       "3  The WHIRLPOOL BATHTUB model AM152JDTS-1Z has s...   \n",
       "4  Iasi is the 4th biggest city in Romania in ter...   \n",
       "\n",
       "                                          rag_answer  \\\n",
       "0  The features of the yellow paper plates mentio...   \n",
       "1  According to Kaighla Um Dayo, a!Cultural Musli...   \n",
       "2  The main characters in the book \"Odd and the F...   \n",
       "3  The WHIRLPOOL BATHTUB model AM152JDTS-1Z has t...   \n",
       "4  Iasi is the 4th biggest city in Romania in ter...   \n",
       "\n",
       "                                       rag_answer_v2  \n",
       "0  The features of the yellow paper plates mentio...  \n",
       "1  According to Kaighla Um Dayo, a \"Cultural Musl...  \n",
       "2  The main characters in the book \"Odd and the F...  \n",
       "3  The WHIRLPOOL BATHTUB model AM152JDTS-1Z has t...  \n",
       "4  Iasi is the 4th biggest city in Romania in ter...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['rag_answer_v2'] = df_sample['question'].apply(rag_answer_v2)\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertScore F1 (без дополнительной проверки релевантности): 0.9309\n"
     ]
    }
   ],
   "source": [
    "avg_f1_v2 = compute_bertscore(df_sample['rag_answer_v2'].tolist(), df_sample['answer'].tolist())\n",
    "print(f\"BertScore F1 (без дополнительной проверки релевантности): {avg_f1_v2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗Полный код (с оптимизациями видеопамяти, с re-ranking, с кэшированием ответов) - смотрите в проекте❗\n",
    "\n",
    "🏷️ Более глубокие **улучшения**я возможностей, качества и оптимизации требуют: \n",
    "1. 🚀 Достаточные **вычислительные мощности**\n",
    "2. 📖 **Доменную область** (для предъявления требований к очистке текста, используемой LLM-модели, используемой sentence-модели и т.д.)\n",
    "3. 🔄 **Наличие Flow**(MLflow\\Airflow\\Kubeflow) для проведения и логирования экспериментов\n",
    "\n",
    "## 📣 Выводы:\n",
    "\n",
    "1. Построена рабочая RAG-система, способная генерировать ответы, основываясь на релевантных документах (тестовых текстах, в данном случае).\n",
    "\n",
    "2. Использование дополнительного шага для определения релевантных документов (через DOC_RETRIEVAL_PROMPT) может улучшить качество ответа (что должно подтвердиться на более малой LLM-модели при сравнении BertScore и на более реальных текстах\\документах)\n",
    "\n",
    "3. Выбор между подходами (с дополнительной фильтрацией и без неё) зависит от задачи и требований к точности.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
